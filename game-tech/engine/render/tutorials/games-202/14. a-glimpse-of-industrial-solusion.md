# A Glimpse of Industrial Solusion

#### Spatiotemporal Variance-Guided Filtering （SVGF ）

时空上的双边滤波，一种当期效果最好的联合双边滤波

- Depth
  - 以深度值，根据贡献函数得到对当前点的贡献
  - 考虑贡献点在切平面法线方向上的深度，而不是朝向摄像机方向的深度
  - ![image-20230329112311733](https://image-1253155090.cos.ap-nanjing.myqcloud.com/202303291123837.png)
- Normal
  - 用两点法线的点积判断是否相互贡献大
  - 一般用宏观的法线而不是法线纹理
  - ![image-20230329112647530](https://image-1253155090.cos.ap-nanjing.myqcloud.com/202303291126629.png)
- Color
  - 一般认为两点间的颜色差异大，就是边缘不需要模糊，滤波核要小
  - 但是由于噪声的存在，不能把噪声认为是边缘，需要被滤波掉
  - 用灰度表示差异，用方差防止噪声，灰度或者方差越大贡献能力越低
  - ![image-20230329112907697](https://image-1253155090.cos.ap-nanjing.myqcloud.com/202303291129766.png)

不足

- SVGF 更倾向于过度模糊
- 由于有时间上的滤波，可能会拖影

#### Recurrent denoising AutoEncoder （RAE）

基于 G-Buffer 和神经网络的图像降噪![image-20220309184939045](https://image-1253155090.cos.ap-nanjing.myqcloud.com/202303291120957.png)

- 使用 AutoEncoder 结构，
- 使用 G-Buffer 以及上一帧的图像信息
- 可能出现 Ghosting，来回抖，看起来像沸腾的水
- RAE 可以在任意数量的 SPP 中运行
- 英伟达 RAE 去掉了时间上的自循环部分
- 没有用到 MotionVector

SVGF 比 RAE 好得多

![image-20230329113841095](https://image-1253155090.cos.ap-nanjing.myqcloud.com/202303291138187.png)



#### Temporal Anti-Aliasing （TAA)

- 四帧一个循环，每帧都进行四分之一个采样
- ![image-20220309185009121](https://image-1253155090.cos.ap-nanjing.myqcloud.com/202303291420881.png)
- 移动的物体使用 Motion vector 找到上一帧着色像素对应的屏幕位置
- 对于 Jitter sampling pattern 的处理和 RTRT filter 基本一致

#### Space Anti-Aliasing

- SSAA ：渲染高分辨率的纹理后，双线性插值降采样,四倍计算开销
- MSAA ：
  - 在同个像素对于每个对这个像素参与贡献的三角形都会进行采样，在硬件光栅化的时候实现![image-20220309185035560](https://image-1253155090.cos.ap-nanjing.myqcloud.com/202303291442648.png)
  - 对于采样点的复用![image-20220309185143137](https://image-1253155090.cos.ap-nanjing.myqcloud.com/202303291442664.png)
- FXAA -> MLAA -> SMAA ：都是同样的算法，基于图像的抗锯齿
  - SMAA：Enhanced subpixel morphological AA 图象矢量化，提取为无限分辨率，离散变连续![image-20220309185218053](https://image-1253155090.cos.ap-nanjing.myqcloud.com/202303291442652.png)

G-Buffer 不能进行抗锯齿，一定是得走样的

#### Temporal Super Resolution 超分辨率方案

- DLSS ：基于当前输出的图像信息和时间上的图像信息

#### 避免没有意义的着色

##### Deferred Shading 延时渲染

- 只 shading 可见的 Fragment ，通过 GBuffer 中的 Depth Buffer 时间
- 光栅化两次，第一次着色 G-Buffer，第二次通过了深度测试才着色 ColorBuffer
- 延时着色也只能对写入深度的不透明物体起作用，前向渲染需要在延时着色之后执行。

##### Deferred Lighting 延时光照 （这块是我自己的理解课外的内容）

- 延时光照是延时渲染理论的最常用的应用
- 在默认都是 PBR 着色的时候，只需要将 PBR 着色所需的所有数据存储在 G-Buffer 内
- 光照着色时通过 G-Buffer 内的数据完成所有像素点着色
- 优点是速度快，一个材质渲染整个屏幕上的所有像素
- 缺点是所需 G-Buffer 数量多，着色材质需求不灵活

#### Tiled Shading

- ![image-20220309185301500](https://image-1253155090.cos.ap-nanjing.myqcloud.com/202303291506052.png)
- 屏幕中的每个条不会被所有的光源影响
- Tiled Shading 在 deferred shading 的基础上，对所需的光源做优化

#### Clustered Shading

- ![image-20220309185309838](https://image-1253155090.cos.ap-nanjing.myqcloud.com/202303291506056.png)
- 深度上继续切片
- 这两渲染管线都是在延时渲染中基于 G-Buffer 实现的，此时已经没有网格物体，三角形的概念了

### Level of Detail Solution

多层次细节 ：近处精细，远处粗糙，再远不可见

- Cascade shadow map
- Cascade LPV
- 关键点在于 cascade 过度，最好对其进行过度

![image-20230329151205323](https://image-1253155090.cos.ap-nanjing.myqcloud.com/202303291512399.png)

- 使用多张 ShadowMap
- 离摄像机越远的区域采样表示范围越大的 ShadowMap

#### Geometry LOD

- Nanite，UE5 的无限精度几何体 LOD 算法，自己写了一套光栅化管线，判断在什么层级使用哪种方式表现物体，比如远的直接用贴图，近的用 LOD
- LOD 方法最大的问题是在线性插值不好起作用时的精度突变
- 可以采用 TAA 来模糊突变
- 可以考虑三角形的调度，纹理的调度，虚拟纹理
- 几何纹理也可以来表示 Geometry

### Global illumination Solution

- 全部实时光追太慢，采用混合模式的性能光追
- 先光栅化，再 SSR，再 RTRT
- 用场景 SDF Trace 光线，RSM 反光手电
- DDGI，用 probe 记录并发射间接光，光照探针，
- 最后使用光线追踪低模物体
- Lumen 是全局光照，是以上方式的结合![image-20230329152055485](https://image-1253155090.cos.ap-nanjing.myqcloud.com/202303291520556.png)